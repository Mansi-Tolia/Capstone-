---
title: "Untitled"
author: "Lyufan Pan"
date: "March 19, 2020"
output: html_document
---

# Student Loan Default Rate

-----

Load those libraries!!
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(corrplot)
library(factoextra)
library(readr)
library(matrixStats)
library(randomForest)
```

# Data cleaning
```{r message=FALSE, warning=FALSE}
#load
scorecard <- readRDS("~/Desktop/cleaned_scorecard.rds")
ipeds <- read_csv("~/Desktop/ipeds.csv")

#clean
names(scorecard) <- tolower(names(scorecard))
names(ipeds) <- tolower(names(ipeds))

#merge datasets based on unitid and year
combined <- merge(ipeds, scorecard, by = c("unitid", "year"))

#remove empty columns or duplicates 
combined$countycd <- NULL
combined$countynm <- NULL
combined$locale2 <- NULL
combined$`institution name` <- NULL
combined$opeid <- NULL
combined$opeid6 <- NULL
combined$city <- NULL

#combine default rates
combined$default <- rowMeans(combined[,c("cdr2","cdr3")], na.rm = T)
```

-----

## Kmeans on PCIP
```{r}
#kmeans cluster analysis on pcip
combined %>% select(starts_with("pcip"), "unitid", 'year') -> pcip

#filter out empty rows
pcip <- pcip[rowSums(is.na(pcip)) != max(rowSums(is.na(pcip))), ]

#kmeans - 4clusters
p <- pcip %>% select(-c("unitid", 'year')) %>% scale()
k4 <- kmeans(p, centers = 4, iter.max = 25, nstart = 25)
#fviz_cluster(k4, data = p)

#check table of clusters
table(k4$cluster)

#add cluster assignment and drop all pcip cols
pcip$cluster <- k4$cluster
pcip1 <- pcip %>% select(unitid, year, cluster)

# merge to combined
df_k4cluster <- inner_join(combined, pcip1, by = c("unitid", "year") )
```


# PCA on PCIP
```{r}
## generate the correlation matrix
pcip %>% 
  select(-unitid, -cluster) -> pcip2

pcip_cor <- cor(pcip2)

corrplot(pcip_cor, 
         method = "color", 
         type="upper", 
         diag=F,
         order = "hclust")
```

Learned that PCIP only really explain about 12% of the variance in the data, maybe let's not use them or rely on them heavily.
```{r}
# pca
pcip_pca = prcomp(pcip2, center=T, scale=T)
fviz_screeplot(pcip_pca, addlables = T, ylim=c(0, 20))
get_eigenvalue(pcip_pca)

#visualize
fviz_pca_var(pcip_pca, col.var = "contrib")
fviz_contrib(pcip_pca, choice = "var")
fviz_contrib(pcip_pca, choice = "var", axes = 2)
fviz_contrib(pcip_pca, choice = "var", axes = 3)
```





# Experimenting with data loss based on `NA` removal
```{r}
# remove columns with less than X% NA
twenty <- combined[, which((colSums(is.na(combined)) / nrow(combined)) > 0.2) ]
fifty <- combined[, which((colSums(is.na(combined)) / nrow(combined)) > 0.5) ]
seventy <- combined[, which((colSums(is.na(combined)) / nrow(combined)) > 0.7) ]
```



# Imputation - create various copies of `combined` using different imputation methods

1. Impute column-wise median values grouped by year
```{r}
medians_by_year <- function(df){
  
  #select only numeric columns
  numeric <- df %>% select_if(is.numeric)
  
  #calculate col-wise medians grouped by the year
  medians <- numeric %>%
    group_by(year) %>%
    summarise_at(vars(-unitid), funs(median(., na.rm=TRUE)))
  
  #pivot those bad boys
  numeric_long <- pivot_longer(numeric, npt412:tail(names(df),1))
  medians_long <- pivot_longer(medians, npt412:tail(names(df),1))
  
  #join by identifying year and name
  joined <- left_join(numeric_long, medians_long, by = c("year", "name"))
  
  #keep only filled value
  joined$lyufan <- ifelse(is.na(joined$value.x) == T, joined$value.y, joined$value.x)
  
  #get rid of the old data
  joined$value.x <- NULL
  joined$value.y <- NULL
  
  #new df!
  df_medians <- pivot_wider(joined, names_from = name, values_from = lyufan)
  
  #return
  return(df_medians)
}

#no cluster
df_medians <- medians_by_year(combined)

#check NAs
#colSums(is.na(df_medians))

#get rid of anything left that has over 10k NAs
df_medians <- df_medians[, colSums(is.na(df_medians)) < 10000]

#with cluster
df_medians_c <- medians_by_year(df_k4cluster)
```

2. Replace all NA values in original df with 0 (uni didn't report them or keep track scenario)
```{r}
#school didn't report it/change default NAs to 0
replace_na(combined, 0)
```

3. Combine `df_medians` an replace with 0
```{r}
df_medians[is.na(df_medians), ] <- 0
```






# Function
Create a function that takes in a dataframe (some version of combined after imputing), runs a model (RF), and records out-of-sample MSE on a log.  
function(dataframe version, model name, other params)

TO DO: transform RF to a function that can take in versions of our data below
```{r}
##THIS STILL HAS BUGS AND NEED TO BE FIXED


set.seed(1234)
d_rf <- df_medians
d_rf$train <- sample(c(0, 1), nrow(d_rf), replace = TRUE, prob = c(0.2, 0.8))
d_rf_test <- d_rf %>% filter(train == 0)
d_rf_train <- d_rf %>% filter(train == 1)

## Cleaning
cat_name <- names(d_rf)
cat_name <- cat_name[!cat_name %in% c("default","cdr2","cdr3","unitid", "zip","stabbr","instnm", "train")]
loopformula <- "cdr2 ~ 1"
for (name in cat_name) {
loopformula <- paste(loopformula, "+", name, sep = "")
}
f_rf <- as.formula(loopformula)

#Train/Test
x1_train <- model.matrix(f_rf, d_rf_train)[, -1]
y_train <- d_rf_train$default
x1_test <- model.matrix(f_rf, d_rf_test)[, -1]
y_test <- d_rf_test$default

#RF fit
fit_rf <- randomForest(f_rf,
d_rf_train,
ntree=10,
do.trace=T)

#Plot RF fit
varImpPlot(fit_rf)

#Predict
yhat_rf_train <- predict(fit_rf, d_rf_train)
mse_rf <- mean((yhat_rf_train -d_rf_train$default) ^ 2)
yhat_rf_test <- predict(fit_rf, d_rf_test)
mse_rf_test <- mean((yhat_rf_test - d_rf_test$default) ^ 2)
```



```{r}
loopformula <- "CDR3 ~ 1"
for (name in cat_name) {
loopformula <- paste(loopformula, "+", name, sep = "")
}
f_rf <- as.formula(loopformula)

#Train/Test
x1_train <- model.matrix(f_rf, d_rf_train)[, -1]
y_train <- d_rf_train$CDR3
x1_test <- model.matrix(f_rf, d_rf_test)[, -1]
y_test <- d_rf_test$CDR3

#RF fit
fit_rf <- randomForest(f_rf,
d_rf_train,
ntree=10,
do.trace=T)

#Plot RF fit
varImpPlot(fit_rf)

#Predict
yhat_rf_train <- predict(fit_rf, d_rf_train)
mse_rf <- mean((yhat_rf_train -d_rf_train$CDR3) ^ 2)
yhat_rf_test <- predict(fit_rf, d_rf_test)
mse_rf_test <- mean((yhat_rf_test - d_rf_test$CDR3) ^ 2)
```
