---
title: "Untitled"
author: "Lyufan Pan"
date: "March 19, 2020"
output: html_document
---
Load those libraries!!
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(corrplot)
library(factoextra)
library(readr)
library(matrixStats)
```

# Data cleaning
```{r}
#load
scorecard <- readRDS("cleaned_scorecard.rds")
ipeds <- read_csv("ipeds.csv")

#clean
names(scorecard) <- tolower(names(scorecard))
names(ipeds) <- tolower(names(ipeds))

#merge datasets based on unitid and year
combined <- merge(ipeds, scorecard, by = c("unitid", "year"))

#remove empty columns or duplicates 
combined$countycd <- NULL
combined$countynm <- NULL
combined$locale2 <- NULL
combined$`institution name` <- NULL
combined$opeid <- NULL
combined$opeid6 <- NULL
combined$city <- NULL
```

# Kmeans on PCIP
```{r}
#kmeans cluster analysis on pcip
combined %>% select(starts_with("pcip"), "unitid") -> pcip

#filter out empty rows
fil <- rowSums(is.na(pcip)) != max(rowSums(is.na(pcip)))
pcip <- pcip[fil,]

#kmeans - 4clusters
p <- scale(pcip[,-1])
k4 <- kmeans(p, centers = 4, iter.max = 25, nstart = 25)
#fviz_cluster(k4, data = p)

#check table of clusters
table(pcip$cluster)

#add cluster assignment and drop all pcip cols
pcip$cluster <- k4$cluster
pcip1 <- pcip %>% select(unitid, cluster)

# merge to combined
merge(combined, pcip1, by = "unitid" )
```

# PCA on PCIP
```{r}
## generate the correlation matrix
pcip %>% 
  select(-unitid, -cluster) -> pcip2

pcip_cor <- cor(pcip2)

corrplot(pcip_cor, 
         method = "color", 
         type="upper", 
         diag=F,
         order = "hclust")
```

```{r}
## pca
pcip_pca = prcomp(pcip2, center=T, scale=T)
fviz_screeplot(pcip_pca, addlables = T, ylim=c(0, 20))
get_eigenvalue(pcip_pca)
```

```{r}
fviz_pca_var(pcip_pca, col.var = "contrib")
fviz_contrib(pcip_pca, choice="var")
fviz_contrib(pcip_pca, choice="var", axes = 2)
fviz_contrib(pcip_pca, choice = "var", axes = 3)
```

```{r}

```


# Experimenting with data loss based on `NA` removal
```{r}
# remove columns with less than X% NA
twenty <- combined[, which((colSums(is.na(combined)) / nrow(combined)) > 0.2) ]
fifty <- combined[, which((colSums(is.na(combined)) / nrow(combined)) > 0.5) ]
seventy <- combined[, which((colSums(is.na(combined)) / nrow(combined)) > 0.7) ]
```



# Imputation - create various copies of `combined` using different imputation methods
Impute column-wise median values grouped by year
```{r}
#imputation
combined %>%
  select_if(is.numeric) %>%
  group_by(year) %>%
  summarise_at(vars(-unitid), funs(median(., na.rm=TRUE)))
```



# Function
Create a function that takes in a dataframe (some version of combined after imputing), runs a model (RF), and records out-of-sample MSE on a log.  
function(dataframe version, model name, other params)






```{r}
#load
data <- data.table(readRDS("~/Desktop/combined.rds"))

#combine default rates
data$default <- rowMeans(data[,c("CDR2","CDR3")], na.rm = T)

#school didn't report it/change default NAs to 0
data$default[is.na(data$default)] <- 0
```

```{r}
skimr::skim(data)
```







```{r}
#data[data==999] <- NA
```



```{r}
data %>% select(starts_with("PCIP")) -> pcip
pcip <- na.omit(pcip)

pcip_cor <- cor(pcip)

corrplot(pcip_cor,
         method = "color",
         type = "upper",
         diag = F,
         order = "hclust",
         rm.na = T)
```

```{r}
data %>% select(starts_with("PCIP"), CDR2) -> data1
summary(lm(CDR2 ~., data1))
```

```{r}
data %>% 
  select_if(is.numeric) %>%
  select(-UnitID, -OPEID, -starts_with("PCIP")) -> data2
summary(lm(CDR2 ~ ., data2))
```

```{r}
# data[!is.na(default),] -> data2
```

```{r}
# install.packages("randomForest")
library(randomForest)
set.seed(1234)
d_rf <- data
d_rf$train <- sample(c(0, 1), nrow(d_rf), replace = TRUE, prob = c(0.2, 0.8))
d_rf_test <- d_rf %>% filter(train == 0)
d_rf_train <- d_rf %>% filter(train == 1)

## Cleaning
cat_name <- names(d_rf)
cat_name <- cat_name[!cat_name %in% c("default","CDR2","CDR3","UnitID", "Institution Name", "ZIP","STABBR","INSTNM", "train","OPEID", "OPEID6")]
loopformula <- "default ~ 1"
for (name in cat_name) {
loopformula <- paste(loopformula, "+", name, sep = "")
}
f_rf <- as.formula(loopformula)

#Train/Test
x1_train <- model.matrix(f_rf, d_rf_train)[, -1]
y_train <- d_rf_train$default
x1_test <- model.matrix(f_rf, d_rf_test)[, -1]
y_test <- d_rf_test$default

#RF fit
fit_rf <- randomForest(f_rf,
d_rf_train,
ntree=10,
do.trace=T)

#Plot RF fit
varImpPlot(fit_rf)

#Predict
yhat_rf_train <- predict(fit_rf, d_rf_train)
mse_rf <- mean((yhat_rf_train -d_rf_train$default) ^ 2)
yhat_rf_test <- predict(fit_rf, d_rf_test)
mse_rf_test <- mean((yhat_rf_test - d_rf_test$default) ^ 2)
```
```{r}
loopformula <- "CDR3 ~ 1"
for (name in cat_name) {
loopformula <- paste(loopformula, "+", name, sep = "")
}
f_rf <- as.formula(loopformula)

#Train/Test
x1_train <- model.matrix(f_rf, d_rf_train)[, -1]
y_train <- d_rf_train$CDR3
x1_test <- model.matrix(f_rf, d_rf_test)[, -1]
y_test <- d_rf_test$CDR3

#RF fit
fit_rf <- randomForest(f_rf,
d_rf_train,
ntree=10,
do.trace=T)

#Plot RF fit
varImpPlot(fit_rf)

#Predict
yhat_rf_train <- predict(fit_rf, d_rf_train)
mse_rf <- mean((yhat_rf_train -d_rf_train$CDR3) ^ 2)
yhat_rf_test <- predict(fit_rf, d_rf_test)
mse_rf_test <- mean((yhat_rf_test - d_rf_test$CDR3) ^ 2)
```


```{r}
colSums(is.na(pcip))/nrow(pcip)
```


```{r}
hist(data$CDR2, main = "Histogram of two-year cohort default rate",
     xlab = "Two-year cohort default rate")
```

```{r}
hist(data$CDR3, main = "Histogram of three-year cohort default rate",
     xlab = "Three-year cohort default rate")
```

```{r}
ggplot(data, aes(CDR2, CDR3, color = as.factor(year))) +
  geom_point()
```


```{r}
## generate the correlation matrix
data3 = data %>%
  select_if(is.numeric) %>%
  select(-UnitID, -OPEID)

data_cor <- cor(data3)

corrplot(data_cor,
         method = "color",
         type = "upper",
         diag = F,
         order = "hclust",
         rm.na = T)
```

```{r}
ggplot(data, aes(x = year, y = CDR2, group = year))+
  geom_boxplot() +
  scale_x_continuous(breaks=seq(min(data$year), max(data$year), 1))+
  labs(x = "Year", y="two-year cohort default rate",
       title = "Boxplot of two-year cohort default rate ")
```

```{r}
ggplot(data, aes(x = year, y = CDR3, group = year))+
  geom_boxplot() +
  scale_x_continuous(breaks=seq(min(data$year), max(data$year), 1))+
  labs(x = "Year", y="Three year cohort default rate",
       title = "Boxplot of three year cohort default rate")
```

```{r}
ggplot(data, aes(x = GRRTWH, y = mean(CDR2,na.rm = T)))+
  geom_bar(stat = "identity")
```

```{r}
ggplot(data, aes(x = REGION, y = GRRTWH, group = REGION))+
  geom_boxplot()+
  scale_x_continuous(breaks=seq(0, 8, 1))
```


```{r}
## pca
data_pca = prcomp(data, center=T, scale=T)

fviz_screeplot(data_pca, addlables = T, ylim=c(0, 50))
get_eigenvalue(data_pca)
```

